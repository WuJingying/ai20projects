<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });
</script>
#Task5   AIBooks
## 任务描述  
* 选择Task5(AIbooks)，选择的书为Artificial Intelligence Machine Learning and Deep Learning  
* 本书分6个章节，包括3个附录。
    * 人工智能概论  
    * 机器学习概论  
    * 机器学习中的分类器  
    * 深度学习概论  
    * 深度学习：RNN和LSTM模型 
    * NLP和强化学习  
    * Keras介绍
    * tf2介绍
    * pandas介绍  
* 已经完成的部分：序言、目录、第一章、第二章  

##一、人工智能概论（报告人：武婧颖）
&emsp;&emsp;本章对人工智能的基本概念、涉及的主要算法、主要应用、相关子领域进行了介绍。
###1.人工智能是什么？
 - 斯特恩伯格：智能是个人从经验中学习、推理、习得重要信息以及应对日常生活需求的认知能力。
 - 拉斐尔：人工智能是一门科学，它让机器来做一些原本需要人类来完成的事情
 - 人工智能的目标：创造表现出与人类相似的思维的计算机软件和硬件系统
####强人工智能和弱人工智能
 - 弱人工智能：将任何表现出智能行为的系统都视为人工智能，仅关注系统的性能
 - 强人工智能：一个表现出智能行为的系统应当基于人类使用的方法，关注系统的结构
###2.图灵测试
 - 游戏测试：提问者提问，回答者回答。提问者评估得到的回答，以确定他是在与人交流还是与机器交流
 - 如果电脑欺骗了提问者，它就通过了图灵测试
### 3.启发法
 - 本质：解决问题的经验法则，一系列能多次使问题解决的指导方法
 - 一种寻找近似解的方法
#### 遗传算法
 - 模仿自然选择过程的启发法
 - 选择最合适的个体（分支）进行繁殖（扩展），以产生下一代（下一个节点）
### 4.知识表示
 - 人工智能系统要获取和存储知识，以处理知识并产生智能结果，就需要识别和表示知识的能力
 - 基于逻辑的方法：运用逻辑解决问题
 - 语义网络：复杂的图形化知识表示方法
### 5.人工智能和游戏
 - 使用人工智能方法开发计算机游戏：国际象棋、跳棋、围棋、奥赛罗、双陆棋、扑克、桥牌等
 - 象棋程序的发展：
  -Deep Thought
  -Deep Blue
  -Deeper Blue
  -奇努克程序
  -AlphaZero：AlphaGo的继承者，拥有属于自己的不同于人类的下棋策略，100%自学
### 6.专家系统
 - 特点：知识库与推理机的分离、知识与搜索技术的关系、推理和不确定性等
 - 著名的专家系统
   -MYCIN：调查传染性血液疾病
   -PROSPECTOR：矿物勘探
   -XCON：帮助配置电路板
   -CUIDON：辅导系统
   -TEIRESIAS：针对MYCIN的知识获取工具
   -HEARSAY I&HEARSAY II：使用黑板结构进行语义理解
   -AM：人工数学系统
### 7.神经计算
- 神经计算的发展
   -人工神经网络模型ANN：不包括学习机制
   -“概念学习规则”迭代算法：在单层网络中确定合适的权重
   -异步网络模型：使用能量函数近似求解NP完全问题
   -反向传播算法：适用于多层网络的学习算法
- 神经网络的应用
   -神经网络也用于控制系统
   -ALVINN：使用反向传播网络，感知高速公路路况并协助控制车辆转向
### 8.进化计算
- 遗传算法：进化计算的一种，使用概率和并行性解决组合问题
- 只能是通过主题与环境相互作用而产生的
### 9.自然语言处理
####Eliza
- 使用反向传播算法
- 学习英语文本的正确发音
- 被精神病学家用来治疗病人
####SHRDLU
- 与人类进行非原创性的对话
- 能够理解英文名伶，并作出适当的反应
- 使用上下文无关语法来帮助解析英文名伶
####解析树
- 展示了组成句子的单词之间的关系
- 给出了句子的语义
####HEARSAY 
- 使用黑板结构，用于语音识别领域
- 各种语言成分和独立知识源可以自由交流
####HWIM
- 使用增强过渡网络来理解口语
####最大绊脚石
- 常识知识问题
- 研究人员尝试建立最大的常识知识库来解决问题
####下一步发展
- 深度学习体系结构：神经网络、学习结构、双向学习结构
- 深度强化学习
### 10.生物信息学
- 计算机科学的算法和技术在分子生物学中的应用
- 主要涉及生物数据的管理和分析
### 11.AI的主要部分
####机器学习 ML
- 学习类型：监督学习、半监督学习、无监督学习、强化学习
- 算法：分类器、回归、聚类、深度学习
####强化学习 RL
- 使用试错法
- 深度强化结合了深度学习和强化学习的优点
- 使用神经网络
####机器人技术
####问题
- 职业偏见
- 检测性别偏见
- 伦理问题，如失业和机器人权利
### 12.小结
- 人工智能，强弱人工智能，智能图灵测试
- 启发式算法
- 遗传算法
- 知识表示
- 人工智能的应用：游戏和专家系统
- 神经计算
- 进化计算
- 自然语言处理
- 生物信息学
- 人工智能的主要子领域：自然语言处理、机器学习、深度学习、强化学习、深度强化学习


---
##二、机器学习概论（报告人：李逸博）
&emsp;&emsp;本章介绍了机器学习领域的很多概念，包括机器学习的简介、类型、具体的操作方法（包括特征工程、降维处理、数据集的使用、正则化等）以及模型的度量（包括度量标准、度量统计量及其计算），同时还介绍了线性回归的方法。在本章的最后，介绍了实际的应用方法，例如用Numpy和Matplotlib绘制散点图、做线性回归；用np.linspace()近似处理线性数据并计算均方误差；用keras进行线性回归。  
&emsp;&emsp;我对第二章的内容进行了总结。总结内容如下。  


## 1.机器学习相关概念  
### 1.1 机器学习的定义
* 是人工智能的核心，是使计算机具有智能的根本途径。  
* 机器学习是对能通过经验自动改进的计算机算法的研究。
* 机器学习是用数据或以往的经验，以此优化计算机程序的性能标准。  
### 1.2 机器学习的类型
* 监督学习  
&emsp;&emsp;数据集中的数据点有标签。例如MNIST数据集标签为图片中显示的数字；Titanic数据集中是否幸存为其标签；房地产数据集中标签为房价。  
* 无监督学习  
&emsp;&emsp;数据为没有标记的数据，典型例子为聚类算法。无监督学习的算法有层次聚类分析、主成分分析、核主成分分析等。  
* 半监督学习  
&emsp;&emsp;监督学习和无监督学习的结合：有些数据点被标记，有些没有被标记。  
### 1.3 机器学习算法的类型  
* 回归  
&emsp;&emsp;用于预测数量的有监督学习技术。例如：预测股票价格等。
* 分类  
&emsp;&emsp;用于预测分类数量的有监督学习技术。例如：检测是否为垃圾邮件、识别数字（MNIST数据集）等。  
* 聚类  
&emsp;&emsp;无监督学习，将相似的数据分在一起。例如：K-均值方法、均值偏移方法、层次聚类分析（HCA）方法等。  
## 2.机器学习流程  
### 2.1 机器学习的任务流程  
*  获取数据集
*	数据清洗
*	特征选择
*	降维处理
*	算法选择
*	训练模型
*	测试模型
*	微调模型
*	获取模型的指标  
### 2.2 特征工程、选择和提取  
&emsp;&emsp;对原始数据进行处理，减少数据集地维数（列数）。  
* 特征工程  
&emsp;&emsp;对于特定的任务，基于现在的特征的组合确定新的特征组合的过程。 
* 特征选择  
&emsp;&emsp;选择数据集中的属性。
* 特征提取  
&emsp;&emsp;从生成原始特征组合的函数中创建新的特征。
### 2.3 降维  
* 主成分分析法 （PCA)  
&emsp;&emsp;主成分是数据集中初始变量的线性组合的新成分。并且，这些成分是不相关的，最有意义或最重要的信息都包含在这些新的成分中。PCA使用方差度量信息：方差越大、分量越重要。  
&emsp;&emsp;PCA可以确定协方差矩阵的特征值和特征向量，并构造一个新矩阵，矩阵的每一列为特征向量，根据最左侧的列中的自大特征值从左到右排序，直到最右边的特征向量也具有最小的特征值。  
* 协方差矩阵  
&emsp;&emsp;
协方差矩阵$C$是一个NxN的矩阵，主对角线上的值为变量$X1, X2, . . ., Xn$。矩阵$C$上的其他值是每对变量$Xi$和$Xj$的协方差。  求变量X和变量Y的协方差公式是求方差公式的推广，公式如下所示：  
$$covariance(X,Y) = \frac{\sum(x-xbar)*(y-ybar)}{n}$$  
### 2.4 数据集  
* 训练集  
* 测试集
* 交叉验证  
1、将数据集拆分为大小相等的k个子集  
2、选择一个子集测试，其余子集用于训练  
3、对其他k-1个子集重复步骤2  
### 2.5 数据标准化  
&emsp;&emsp;为线性缩放技术。  
&emsp;&emsp;假设一个数据集有${X_1,X_2,X_3,...,X_n}$以及以下两个量：  
$$Min_x = minimum(X_i)$$  
$$Max_x = maximum(X_i)$$ 
&emsp;&emsp;计算一组新的$X_i$如下所示:  
$$X_i = \frac{X_i-Min_x}{Max_x-Min_x}$$
&emsp;&emsp;这里得到的$X_i$就是缩放后的结果，它是介于0和1之间的。
### 2.6 度量模型的度量标准  
* R方  
&emsp;&emsp;$R^2 = \frac{(TSS-RSS)}{TSS}$  
&emsp;&emsp;&emsp; = 解释变化/总变化  
&emsp;&emsp;&emsp; = 1-未解释的变化/总变化  
&emsp;&emsp;其中,TSS为实际值与其平均值之差的平方和。
RSS为残差的平方和，为实际值和预测值之差的平方和。  
* 混淆矩阵  
    * TP: 正确接受
    * FP: 错误接受
    * TN: 正确拒绝
    * FN: 错误拒绝  
    $$precision = TP/(TN + FP)$$   
    $$accuracy	= (TP + TN)/(P + N)$$  
    $$recall= TP/(TP + FN) $$ 
* $P-value$  
&emsp;&emsp;p值是指在一个概率模型中，统计摘要（如两组样本均值差）与实际观测数据相同，或甚至更大这一事件发生的概率。换言之，是检验假设零假设成立或表现更严重的可能性。  
* $F1 score$  
$$F1=2*\frac{precision*recall}{precision+recall} $$
## 3.线性回归  
### 3.1 线性回归  
&emsp;&emsp;线性回归是回归问题中的一种，线性回归假设目标值与特征之间线性相关，即满足一个多元一次方程。通过构建损失函数，来求解损失函数最小时的参数$w$和$b$。通长我们可以表达成如下公式：  
&emsp;&emsp;$\hat{y}=wx+b$  
&emsp;&emsp;$\hat{y}$为预测值，自变量$x$和因变量$y$是已知的，而我们想实现的是预测新增一个$x$，其对应的$y$是多少。因此，为了构建这个函数关系，目标是通过已知数据点，求解线性模型中$w$和$b$两个参数。  
### 3.2 损失函数  
&emsp;&emsp;损失函数定义如下：  
图1公式   
&emsp;&emsp;即预测值与真实值之间的平均的平方距离，统计中一般称其为MSE(mean square error)均方误差。  
### 3.3 均方误差公式（MSE）  
&emsp;&emsp;MSE是真实值与预测值的差值的平方然后求和平均。  
图2  
&emsp;&emsp;范围$[0,+\infty)$，当预测值与真实值完全相同时为0，误差越大，该值越大。  
```python  
import numpy as np
from sklearn import metrics
y_true = np.array([1.0, 5.0, 4.0, 3.0, 2.0, 5.0, -3.0])
y_pred = np.array([1.0, 4.5, 3.5, 5.0, 8.0, 4.5, 1.0])
print(metrics.mean_squared_error(y_true, y_pred)) #107142857142858  
```
## 4.用Numpy和Matplotlib实现的散点图  
### 4.1 调用$numpy$中的$random()$API生成数据集，用$matplotlib$中的$scatter()$API绘制数据集中的点。
```python
import numpy as np
import matplotlib.pyplot as plt

x = np.random.randn(15,1)
y = 2.5*x + 5 + 0.2*np.random.randn(15,1)#扰动技术

print("x:",x)
print("y:",y)

plt.scatter(x,y) plt.show()
```

### 4.2  $trainX$基于$np.linspace()$API，$trainY$利用扰动技术。  
```python
trainX = np.linspace(-1, 1, 11)
trainY = 4*trainX + np.random.randn(*trainX.shape)*0.5

print("trainX: ",trainX) print("trainY: ",trainY)
```
### 4.3 在平面上绘制二次函数  
$x$用$np.linspace()$生成。  
$y$为$x$的函数加上扰动技术产生的数组。  
```python
#see what happens with this set of values: #x = np.linspace(-5,5,num=100)
x = np.linspace(-5,5,num=100)[:,None]
y = -0.5 + 2.2*x +0.3*x**2 + 2*np.random.randn(100,1)
print("x:",x)

plt.plot(x,y)
plt.show()
```
## 5.运用keras进行线性回归  
&emsp;&emsp;神经网络可以用来模拟回归问题，实质上是单输入单输出的神经网络模型。比如：给定一组$X,Y$数据，用一条线来对数据进行拟合，并预测新输入的x的输出值y。 
在本利用"housing.csv"数据集，$Y$为房价，$X$为其他特征。  
&emsp;&emsp;流程如下：  
* 调用$MinMaxScale$（）函数处理X，并将$Y$归一化到-1到1的范围内。  
* 将数据集以7:3的比例划分数据及和测试集。  
* 建立$keras$模型。包含两个全连接层。优化器为"$adam$"，损失函数为均方误差，并指定准确率的度量为$MAE$和$precision$。  
* 将$batch\_size$设置为32，$epoch$设置为40。并调用$tf.keras.wrappers.scikit\_learn. KerasRegressor$函数用于回归模型。  
* 调用$fit()$函数训练模型。对$X\_test$数据集调用$predict()$函数预测测试值。 
* 绘制散点图。  
## 6.总结 
&emsp;&emsp;第二章机器学习概论主要讲了相关概念、任务流程和一些具体的方法。  
&emsp;&emsp;在翻译的过程中，我对机器学习有了更清晰的认识，同时自己阅读英文专业书籍的能力得到了提高。   
&emsp;&emsp;但是由于本书讲的内容大多是概念性的东西，仅仅是入门级别的，所以要想深入了解机器学习算法，还需要进一步查阅资料或阅读其他书籍。  
## 7.规划  
&emsp;&emsp;继续翻译本书或找其他书的部分内容进行翻译。内容主要集中于机器学习和深度学习领域。










